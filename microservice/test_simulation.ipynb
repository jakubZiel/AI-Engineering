{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.core.frame import DataFrame\n",
    "import requests as req\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from mongo_db import TestArchive\n",
    "import sys\n",
    "from pymongo import MongoClient \n",
    "from scipy.stats import ttest_ind\n",
    "from scipy.stats import t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('../data/processed/casted_clearedDF.jsonl' , lines=True)\n",
    "\n",
    "if len(sys.argv) != 2:\n",
    "    test_size = 0.2\n",
    "else : \n",
    "    test_size = float(sys.argv[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "    #prepare data\n",
    "    df = df.drop(columns=[\n",
    "        \"delivery_company\",\n",
    "        \"session_id\",\n",
    "        \"purchase_timestamp\", \n",
    "        \"delivery_timestamp\",\n",
    "        \"product_name\",\n",
    "        \"price\",\n",
    "        \"category_path\",\n",
    "        \"week_day\"\n",
    "        ])\n",
    "\n",
    "    label_city = LabelEncoder()\n",
    "    df['city'] = label_city.fit_transform(df['city'])\n",
    "    label_street = LabelEncoder()\n",
    "    df['street'] = label_street.fit_transform(df['street'])\n",
    "\n",
    "    x = df[['street', 'purchase_week_day_plus_hour', 'city', \"user_id\"]]\n",
    "    y = df['delivery_time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data\n",
    "_, x_test, _, y_test = train_test_split(x, y, test_size = test_size, random_state = 0)\n",
    "\n",
    "number_of_requests = len(x_test)\n",
    "\n",
    "x_test : DataFrame = x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reset database before running A/B test\n",
    "test_archive = TestArchive()\n",
    "test_archive.reset_collections()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#group y values for each test group\n",
    "test_group_a = []\n",
    "test_group_b = []\n",
    "\n",
    "for index, row in x_test.iterrows():\n",
    "    if row['user_id'] % 2 == 0:\n",
    "        test_group_a.append(y_test[index])\n",
    "    else :\n",
    "        test_group_b.append(y_test[index])\n",
    "\n",
    "\n",
    "x_test = x_test.values.tolist()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#perform ab tests\n",
    "url = 'http://localhost:8000/ab_test?user_id='\n",
    "\n",
    "for i in range(0, number_of_requests):\n",
    "    record = x_test[i]\n",
    "    data = {\n",
    "        'street' : record[0],\n",
    "        'purchase_week_day_plus_hour' : record[1],\n",
    "        'city' : record[2]\n",
    "    }\n",
    "    req.post(url + str(record[3]), json=data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the results\n",
    "test_archive = TestArchive()\n",
    "\n",
    "predictions_a = []\n",
    "for ele_a in test_archive.find_group('group_a'):\n",
    "    predictions_a.append(ele_a['prediction'])\n",
    "predictions_b = []\n",
    "for ele_b in test_archive.find_group('group_b'):\n",
    "    predictions_b.append(ele_b['prediction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "640\n",
      "640\n",
      "767\n",
      "767\n"
     ]
    }
   ],
   "source": [
    "#calculate quality metrics\n",
    "predictions_a = pd.Series(predictions_a)\n",
    "predictions_b = pd.Series(predictions_b)\n",
    "\n",
    "test_group_a = pd.Series(test_group_a)\n",
    "test_group_b = pd.Series(test_group_b)\n",
    "\n",
    "\n",
    "print(len(predictions_a))\n",
    "print(len(test_group_a))\n",
    "\n",
    "print(len(predictions_b))\n",
    "print(len(test_group_b))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "correcntess_a = []\n",
    "\n",
    "for index, ele in enumerate(predictions_a):\n",
    "    result = 1 if ele == test_group_a[index] else 0\n",
    "    correcntess_a.append(result)\n",
    "\n",
    "    correcntess_b = []\n",
    "\n",
    "for index, ele in enumerate(predictions_b):\n",
    "    result = 1 if ele == test_group_b[index] else 0\n",
    "    correcntess_b.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stat_t value : 4.255408962779513\n",
      "p-value : 1.112440382678287e-05\n"
     ]
    }
   ],
   "source": [
    "t_stat, p = ttest_ind(correcntess_b, correcntess_a)\n",
    "\n",
    "dof = len(correcntess_b) + len(correcntess_a) - 2\n",
    "\n",
    "print(\"stat_t value : \" + str(t_stat))\n",
    "print(\"p-value : \" + str(t.sf(t_stat, dof)))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
